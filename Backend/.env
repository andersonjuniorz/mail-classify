# ==============================================================
# --------------------- FRONTEND -------------------------------
# ==============================================================
FRONTEND_ORIGIN=http://localhost

# ==============================================================
# -------------------- Treinamento -----------------------------
# ==============================================================

# Local dos datasets de treinameto
DATASET_BASE_PATH=./myApp/data/datasets

# Idiomas disponiveis: en, pt 
# idiomas usados como base de treino
DATASET_LANGUAGES=en, pt


# ==============================================================
# ------------------ Configuracoes da IA -----------------------
# ==============================================================

MODEL_NAME = distilbert-base-multilingual-cased

# Num de categorias que a IA deve prever 
# 'Produtivo','Improdutivo'
NUM_LABELS = 2

# Usei 128, mas reduzi pra 64 pra economizar RAM 
# sequencia de tokens que o modelo processa
MAX_LENGTH = 64

# Reduzi de 8 para 1 para economizar RAM
# Num de amostras (e-mails) que o modelo processa por vez

BATCH_SIZE = 1 
LEARNING_RATE = 2e-5 # A taxa de aprendizado

# Num de vezes que o modelo vai "repassar" 
# por todo treinamento
NUM_EPOCHS = 3


# ==============================================================
# ------------------ Configuracoes da Maquina ------------------
# ==============================================================

# USE_GPU | False - Usar Processador (CPU)
# USE_GPU | True  - Usar Placa de Video (GPU)
USE_GPU=False

# Limite min de VRAM em GB para usar a GPU (USE_GPU=True)
MIN_GPU_VRAM_GB=4.0

# Limite de RAM (MB) para treinamento (caso CPU)

# 16GB RAM = 16384 MB. Sugiro no max 80% da sua RAM total
# Ex: 12GB = 12288 MB. Deixara 4GB para o SO e outros apps
MAX_RAM_MB=12288 # Exemplo: <-- Limite de 12GB (12 * 1024 MB)